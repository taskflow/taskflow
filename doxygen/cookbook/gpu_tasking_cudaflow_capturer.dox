namespace tf {

/** @page GPUTaskingcudaFlowCapturer GPU Tasking (%cudaFlowCapturer)

You can create a %cudaFlow through <i>stream capture</i>, which allows you
to capture information on GPU activities that are submitted to the stream 
managed by a @em %cudaFlowCapturer.

@tableofcontents

@section C7_Capture_a_cudaFlow Capture a cudaFlow

When your program has no access to direct kernel calls but invoke
it through a stream-based interface (e.g., @cuBLAS and @cuDNN library functions),
you can use tf::cudaFlowCapturer to capture the GPU activities into a %cudaFlow.
A %cudaFlowCapturer is similar to a %cudaFlow except it forms a GPU task graph
through <i>stream capture</i>.
You use the method tf::cudaFlowCapturer::on
to capture a sequence of @em asynchronous CUDA operations through the given stream.

The following example creates a CUDA graph that captures two kernel tasks, 
@c task_1 and @c task_2, where @c task_1 (i.e., @c my_kernel_1) 
runs before @c task_2 (i.e., @c my_kernel_2).

@code{.cpp}
#include <taskflow/cudaflow.hpp>

int main() {

  tf::Executor executor;
  tf::Taskflow taskflow;

  tf::Task task = taskflow.emplace([&](tf::cudaFlowCapturer& capturer){
    // capture my_kernel_1 through a stream managed by capturer
    tf::cudaTask task_1 = capturer.on([&](cudaStream_t stream){ 
      my_kernel_1<<<grid_1, block_1, shm_size_1, stream>>>(my_parameters_1);
    }).name("my_kernel_1");
  
    // capture my_kernel_2 through a stream managed by capturer
    tf::cudaTask task_2 = capturer.on([&](cudaStream_t stream){ 
      my_kernel_2<<<grid_2, block_2, shm_size_2, stream>>>(my_parameters_2);
    }).name("my_kernel_2");
  
    // my_kernel_1 runs before my_kernel_2
    task_1.precede(task_2);
  }).name("capturer");

  executor.run(taskflow).wait();

  taskflow.dump(std::cout);

  return 0;
}
@endcode

@dotfile images/cudaflow_capturer_1.dot

The stream object passed to each tf::cudaFlowCapturer::on call may differ,
and it depends on how the internal optimization algorithm maximizes the 
GPU parallelism.

@warning
Inside tf::cudaFlowCapturer::on, you should @em NOT modify the properties of 
the stream argument but use it to capture @em asynchronous GPU operations
(e.g., @c kernel, @c cudaMemcpyAsync).

A %cudaFlowCapturer lives with the callable.
When the executor invoke the capturer callable, it creates the %cudaFlowCapturer
and will destroy it until all internal operations finish.



@section C7_CommonCaptureMethods Common Capture Methods

%cudaFlowCapturer defines a set of methods for capturing common GPU operations,
such as tf::cudaFlowCapturer::kernel, tf::cudaFlowCapturer::memcpy,
tf::cudaFlowCapturer::memset, and so on.
For example, the following code snippet uses these pre-defined methods
to construct a GPU task graph of one host-to-device copy, kernel, 
and one device-to-host copy, in this order of their dependencies.

@code{.cpp}
tf::Task task = taskflow.emplace([](tf::cudaFlowCapturer& capturer){
  // copy data from host_data to gpu_data
  tf::cudaTask h2d = capturer.memcpy(gpu_data, host_data, bytes).name("h2d");

  // capture my_kernel to do computation on gpu_data
  tf::cudaTask kernel = capturer.on([&](cudaStream_t stream){  
    my_kernel<<<grid, block, shm_size, stream>>>(gpu_data, arg1, arg2, ...);
  }).name("my_kernel");

  // copy data from gpu_data to host_data
  tf::cudaTask d2h = capturer.memcpy(host_data, gpu_data, bytes).name("d2h");
  
  h2d.precede(kernel);
  kernel.precede(d2h);
}).name("capturer");
@endcode

@dotfile images/cudaflow_capturer_2.dot

@section C7_CreateACapturerOnASpecificGPU Create a Capturer on a Specific GPU

You can capture a %cudaFlow on a specific GPU by calling tf::Taskflow::emplace_on.
By default, a %cudaFlow runs on the current GPU associated with the caller, 
which is typically 0.
Similar to @ref C6_run_a_cudaflow_on_multiple_gpus,
you can emplace a %cudaFlowCapturer on a specific GPU.

@code{.cpp}
tf::Task task = taskflow.emplace_on([](tf::cudaFlowCapturer& capturer){
  // here, capturer is under GPU device context 2
  // ...
}, 2);
@endcode

The above example creates a capturer on GPU 2. 
When the executor runs the callable, it switches to GPU 2 
and all the functions within the callable are called under this context.

@attention
It is your responsibility to ensure the allocated memory to sit 
in the same context as the capturer.

@section C7_CreateACapturerWithinAcudaFlow Create a Capturer within a cudaFlow

Within a parent %cudaFlow, you can capture a %cudaFlow to form a subflow that 
eventually becomes a @em child node in the underlying CUDA task graph.
The following example defines a captured flow @c task2 of two dependent tasks,
@c task2_1 and @c task2_2, and @c task2 runs after @c task1.

@code{.cpp}
tf::Task task = taskflow.emplace([&](tf::cudaFlow& cf){

  tf::cudaTask task1 = cf.kernel(grid, block, shm, my_kernel, args...)
                         .name("my_kernel");
  
  // task2 forms a subflow in cf and becomes a child node in the underlying 
  // CUDA graph
  tf::cudaTask task2 = cf.capture([&](tf::cudaFlowCapturer& capturer){
    tf::cudaTask task2_1 = capturer.on([&](cudaStream_t stream){  
      my_kernel2<<<grid1, block1, shm_size1, stream>>>(args1...);
    }).name("my_kernel1");  // capture my_kernel1 using the given stream

    tf::cudaTask task2_2 = capturer.on([&](cudaStream_t stream){  
      my_kernel2<<<grid2, block2, shm_size2, stream>>>(args2...);
    }).name("my_kernel2");  // capture my_kernel2 using the given stream 

    task2_1.precede(task2_2);
  }).name("capturer");

  task1.precede(task2);
}).name("cudaFlow");
@endcode

@dotfile images/cudaflow_capturer_3.dot


@section C7_CreateCustomCapturer Create a Custom Capturer

By inheriting tf::cudaFlowCapturerBase, you can create your own capturer.
The tf::cudaFlowCapturer has a factory interface, tf::cudaFlowCapturer::make_capturer,
for users to create custom capturers with lifetimes managed by a parent capturer.
The parent capturer is accessible through tf::cudaFlowCapturerBase::factory.
This is convenient when you need certain objects alive during the capturing.
The following example defines a custom capturer that takes the given
stream from tf::cudaFlowCapturer::on to capture a custom kernel.

@code{.cpp}
class MyCapturer : public tf::cudaFlowCapturerBase {

  public:

  // capture a custom kernel
  tf::cudaTask capture_custom_kernel(args...) {
    return factory()->on([this, args...](cudaStream_t stream){
      invoke_custom_kernel(stream, args...);
    });
  }
};

tf::Task task = taskflow.emplace([&](tf::cudaFlowCapturer& capturer){
  // create a custom capturer, MyCapturer, from the parent capturer (factory)
  MyCapturer* mc = capturer.make_capturer<MyCapturer>();

  tf::cudaTask task_1 = mc->capture_custom_kernel(args...).name("custom_kernel");
  tf::cudaTask task_2 = capturer.on([&](cudaStream_t stream){
    other_kernel<<<grid, block, shm_size, stream>>>(other_args...);
  }).name("other_kernel");

  task_1.precede(task_2);
}).name("capturer");
@endcode

@dotfile images/cudaflow_capturer_1.dot

%Taskflow provides several class interfaces, such as tf::cublasFlowCapturer,
on top of tf::cudaFlowCapturerBase for users to use
external high-performance CUDA libraries together with %Taskflow.

*/

}


