<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.20" xml:lang="en-US">
  <compounddef id="chapter6" kind="page">
    <compoundname>chapter6</compoundname>
    <title>GPU Tasking (cudaFlow)</title>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>Modern scientific computing typically leverages GPU-powered parallel processing cores to speed up large-scale applications. This chapters discusses how to implement CPU-GPU heterogeneous tasking algorithms with <ulink url="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</ulink>.</para>
<sect1 id="chapter6_1C6_Create_a_cudaFlow">
<title>Create a cudaFlow</title>
<para>Taskflow enables concurrent CPU-GPU tasking by leveraging <ulink url="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</ulink>. The tasking interface is referred to as <emphasis>cudaFlow</emphasis>. A cudaFlow is a graph object of type <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> created at runtime similar to dynamic tasking. It manages a task node in a taskflow and associates it with a CUDA Graph. To create a cudaFlow, emplace a callable with an argument of type <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>. The following example implements the canonical saxpy (A·X Plus Y) task graph.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><sp/>1:<sp/>#include<sp/>&lt;taskflow/taskflow.hpp&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/>2:<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/>3:<sp/></highlight><highlight class="comment">//<sp/>saxpy<sp/>(single-precision<sp/>A·X<sp/>Plus<sp/>Y)<sp/>kernel</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/>4:<sp/>__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>saxpy(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>a,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>5:<sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>blockIdx.x*blockDim.x<sp/>+<sp/>threadIdx.x;</highlight></codeline>
<codeline><highlight class="normal"><sp/>6:<sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i<sp/>&lt;<sp/>n)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>7:<sp/><sp/><sp/><sp/><sp/>y[i]<sp/>=<sp/>a*x[i]<sp/>+<sp/>y[i];</highlight></codeline>
<codeline><highlight class="normal"><sp/>8:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/>9:<sp/>}</highlight></codeline>
<codeline><highlight class="normal">10:</highlight></codeline>
<codeline><highlight class="normal">11:<sp/></highlight><highlight class="comment">//<sp/>main<sp/>function<sp/>begins</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">12:<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>main()<sp/>{</highlight></codeline>
<codeline><highlight class="normal">13:</highlight></codeline>
<codeline><highlight class="normal">14:<sp/><sp/><sp/><ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref><sp/>taskflow;</highlight></codeline>
<codeline><highlight class="normal">15:<sp/><sp/><sp/><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor;</highlight></codeline>
<codeline><highlight class="normal">16:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">17:<sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>N<sp/>=<sp/>1&lt;&lt;20;<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>size<sp/>of<sp/>the<sp/>vector</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">18:</highlight></codeline>
<codeline><highlight class="normal">19:<sp/><sp/><sp/><ref refid="cpp/container/vector" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::vector&lt;float&gt;</ref><sp/>hx(N,<sp/>1.0f);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>x<sp/>vector<sp/>at<sp/>host</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">20:<sp/><sp/><sp/><ref refid="cpp/container/vector" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::vector&lt;float&gt;</ref><sp/>hy(N,<sp/>2.0f);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>y<sp/>vector<sp/>at<sp/>host</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">21:</highlight></codeline>
<codeline><highlight class="normal">22:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dx{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>x<sp/>vector<sp/>at<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">23:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dy{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>y<sp/>vector<sp/>at<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">24:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">25:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>allocate_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(</highlight></codeline>
<codeline><highlight class="normal">26:<sp/><sp/><sp/><sp/><sp/>[&amp;](){<sp/>cudaMalloc(&amp;dx,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));}</highlight></codeline>
<codeline><highlight class="normal">27:<sp/><sp/><sp/>);</highlight></codeline>
<codeline><highlight class="normal">28:</highlight></codeline>
<codeline><highlight class="normal">29:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>allocate_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(</highlight></codeline>
<codeline><highlight class="normal">30:<sp/><sp/><sp/><sp/><sp/>[&amp;](){<sp/>cudaMalloc(&amp;dy,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));}</highlight></codeline>
<codeline><highlight class="normal">31:<sp/><sp/><sp/>);</highlight></codeline>
<codeline><highlight class="normal">32:</highlight></codeline>
<codeline><highlight class="normal">33:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaflow<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">34:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>data<sp/>transfer<sp/>tasks</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">35:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N);<sp/><sp/></highlight><highlight class="comment">//<sp/>copy<sp/>hx<sp/>to<sp/>gpu</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">36:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N);<sp/><sp/></highlight><highlight class="comment">//<sp/>copy<sp/>hy<sp/>to<sp/>gpu</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">37:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N);<sp/><sp/></highlight><highlight class="comment">//<sp/>copy<sp/>dx<sp/>to<sp/>cpu</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">38:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N);<sp/><sp/></highlight><highlight class="comment">//<sp/>copy<sp/>dy<sp/>to<sp/>cpu</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">39:</highlight></codeline>
<codeline><highlight class="normal">40:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>saxpy&lt;&lt;&lt;(N+255)/256,<sp/>256,<sp/>0&gt;&gt;&gt;(N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">41:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>kernel<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(</highlight></codeline>
<codeline><highlight class="normal">42:<sp/><sp/><sp/><sp/><sp/><sp/><sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy</highlight></codeline>
<codeline><highlight class="normal">43:<sp/><sp/><sp/><sp/><sp/>);</highlight></codeline>
<codeline><highlight class="normal">44:</highlight></codeline>
<codeline><highlight class="normal">45:<sp/><sp/><sp/><sp/><sp/>kernel.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal">46:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
<codeline><highlight class="normal">48:<sp/><sp/><sp/>});</highlight></codeline>
<codeline><highlight class="normal">49:<sp/><sp/><sp/>cudaflow.<ref refid="classtf_1_1Task_1a331b1b726555072e7c7d10941257f664" kindref="member">succeed</ref>(allocate_x,<sp/>allocate_y);<sp/><sp/></highlight><highlight class="comment">//<sp/>overlap<sp/>memory<sp/>alloc</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">50:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">51:<sp/><sp/><sp/>executor.<ref refid="classtf_1_1Executor_1a81f35d5b0a20ac0646447eb80d97c0aa" kindref="member">run</ref>(taskflow).wait();</highlight></codeline>
<codeline><highlight class="normal">52:</highlight></codeline>
<codeline><highlight class="normal">53:<sp/><sp/><sp/>taskflow.<ref refid="classtf_1_1Taskflow_1a4725d8ea5ff7595d9d71593360538e00" kindref="member">dump</ref>(<ref refid="cpp/io/basic_ostream" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::cout</ref>);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>dump<sp/>the<sp/>taskflow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">54:<sp/>}</highlight></codeline>
</programlisting></para>
<para><dotfile name="/Users/twhuang/Code/taskflow/doxygen/images/saxpy.dot"></dotfile>
</para>
<para>Debrief:</para>
<para><itemizedlist>
<listitem><para>Lines 3-9 define a saxpy kernel using CUDA </para>
</listitem>
<listitem><para>Lines 19-20 declare two host vectors, <computeroutput>hx</computeroutput> and <computeroutput>hy</computeroutput> </para>
</listitem>
<listitem><para>Lines 22-23 declare two device vector pointers, <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> </para>
</listitem>
<listitem><para>Lines 25-31 declare two tasks to allocate memory for <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> on device, each of <computeroutput>N*sizeof(float)</computeroutput> bytes </para>
</listitem>
<listitem><para>Lines 33-48 create a cudaFlow to define a GPU task graph (two host-to-device data transfer tasks, one saxpy kernel task, and two device-to-host data transfer tasks) </para>
</listitem>
<listitem><para>Lines 49-53 define the task dependency between host tasks and the cudaFlow tasks and execute the taskflow</para>
</listitem>
</itemizedlist>
Taskflow does not expend unnecessary efforts on kernel programming but focus on tasking CUDA operations with CPU work. We give users full privileges to craft a CUDA kernel that is commensurate with their domain knowledge. Users focus on developing high-performance kernels using a native CUDA toolkit, while leaving difficult task parallelism to Taskflow.</para>
</sect1>
<sect1 id="chapter6_1C6_Compile_a_cudaFlow_program">
<title>Compile a cudaFlow Program</title>
<para>Use <ulink url="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</ulink> (at least v11.1) to compile a cudaFlow program:</para>
<para><programlisting filename=".shell-session"><codeline><highlight class="normal">~$<sp/>nvcc<sp/>-std=c++17<sp/>my_cudaflow.cu<sp/>-I<sp/>path/to/include/taskflow<sp/>-O2<sp/>-o<sp/>my_cudaflow</highlight></codeline>
<codeline><highlight class="normal">~$<sp/>./my_cudaflow</highlight></codeline>
</programlisting></para>
<para>Our source autonomously enables cudaFlow when detecting a CUDA compiler.</para>
</sect1>
<sect1 id="chapter6_1C6_configure_the_number_of_gpu_workers">
<title>Configure the Number of GPU workers</title>
<para>By default, the executor spawns one worker per GPU. We dedicate a worker set to each heterogeneous domain, for example, host domain and CUDA domain. If your systems has 4 CPU cores and 2 GPUs, the default number of workers spawned by the executor is 4+2, where 4 workers run CPU tasks and 2 workers run GPU tasks (cudaFlow). You can construct an executor with different numbers of GPU workers.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor(17,<sp/>8);<sp/><sp/></highlight><highlight class="comment">//<sp/>17<sp/>CPU<sp/>workers<sp/>and<sp/>8<sp/>GPU<sp/>workers</highlight></codeline>
</programlisting></para>
<para>The above executor spawns 17 and 8 workers for running CPU and GPU tasks, respectively. These workers coordinate with each other to balance the load in a work-stealing loop highly optimized for performance.</para>
</sect1>
<sect1 id="chapter6_1C6_run_a_cudaflow_on_multiple_gpus">
<title>Run a cudaFlow on Multiple GPUs</title>
<para>By default, a cudaFlow runs on the current GPU associated with the caller, which is typically <computeroutput>0</computeroutput>. You can run a cudaFlow on multiple GPUs by explicitly associating a cudaFlow or a kernel task with a CUDA device. A CUDA device is an integer number in the range of <computeroutput>[0, N)</computeroutput> representing the identifier of a GPU, where <computeroutput>N</computeroutput> is the number of GPUs in a system. The code below creates a cudaFlow that runs on GPU <computeroutput>0</computeroutput>.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([]<sp/>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{},<sp/>0);<sp/><sp/></highlight><highlight class="comment">//<sp/>place<sp/>the<sp/>cudaFlow<sp/>on<sp/>GPU<sp/>0</highlight></codeline>
</programlisting></para>
<para>You can place a kernel on a GPU explicitly through the method <ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">tf::cudaFlow::kernel_on</ref> that takes the GPU device identifier in the first argument.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><sp/>1:<sp/>#include<sp/>&lt;taskflow/taskflow.hpp&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/>2:<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/>3:<sp/></highlight><highlight class="comment">//<sp/>saxpy<sp/>(single-precision<sp/>A·X<sp/>Plus<sp/>Y)<sp/>kernel</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/>4:<sp/>__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>saxpy(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>a,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*z)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>5:<sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>blockIdx.x*blockDim.x<sp/>+<sp/>threadIdx.x;</highlight></codeline>
<codeline><highlight class="normal"><sp/>6:<sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i<sp/>&lt;<sp/>n)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>7:<sp/><sp/><sp/><sp/>z[i]<sp/>=<sp/>a*x[i]<sp/>+<sp/>y[i];</highlight></codeline>
<codeline><highlight class="normal"><sp/>8:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/>9:<sp/>}</highlight></codeline>
<codeline><highlight class="normal">10:</highlight></codeline>
<codeline><highlight class="normal">11:<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>main()<sp/>{</highlight></codeline>
<codeline><highlight class="normal">12:</highlight></codeline>
<codeline><highlight class="normal">13:<sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>N<sp/>=<sp/>1&lt;&lt;20;</highlight></codeline>
<codeline><highlight class="normal">14:<sp/><sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">15:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>dx<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">16:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>dy<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">17:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>z1<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">18:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>z2<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">19:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">20:<sp/><sp/><sp/>cudaMallocManaged(&amp;dx,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>unified<sp/>memory<sp/>for<sp/>x</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">21:<sp/><sp/><sp/>cudaMallocManaged(&amp;dy,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>unified<sp/>memory<sp/>for<sp/>y</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">22:<sp/><sp/><sp/>cudaMallocManaged(&amp;z1,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>result<sp/>of<sp/>saxpy<sp/>task<sp/>1</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">23:<sp/><sp/><sp/>cudaMallocManaged(&amp;z2,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>result<sp/>of<sp/>saxpy<sp/>task<sp/>2</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">24:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">25:<sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>i=0;<sp/>i&lt;N;<sp/>++i)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">26:<sp/><sp/><sp/><sp/><sp/>dx[i]<sp/>=<sp/>1;</highlight></codeline>
<codeline><highlight class="normal">27:<sp/><sp/><sp/><sp/><sp/>dy[i]<sp/>=<sp/>2;</highlight></codeline>
<codeline><highlight class="normal">28:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal">29:</highlight></codeline>
<codeline><highlight class="normal">30:<sp/><sp/><sp/><ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref><sp/>taskflow;</highlight></codeline>
<codeline><highlight class="normal">31:<sp/><sp/><sp/><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor;</highlight></codeline>
<codeline><highlight class="normal">32:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">33:<sp/><sp/><sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal">34:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>create<sp/>a<sp/>cudaFlow<sp/>on<sp/>GPU<sp/>0.<sp/>The<sp/>scheduler<sp/>will<sp/>switch<sp/>to<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">35:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>GPU<sp/>context<sp/>0<sp/>when<sp/>running<sp/>this<sp/>callable.</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">36:</highlight></codeline>
<codeline><highlight class="normal">37:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>the<sp/>first<sp/>saxpy<sp/>kernel<sp/>on<sp/>GPU<sp/>1</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">38:<sp/><sp/><sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">kernel_on</ref>(1,<sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z1);</highlight></codeline>
<codeline><highlight class="normal">39:</highlight></codeline>
<codeline><highlight class="normal">40:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>the<sp/>second<sp/>saxpy<sp/>kernel<sp/>on<sp/>GPU<sp/>3</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">41:<sp/><sp/><sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">kernel_on</ref>(3,<sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z2);</highlight></codeline>
<codeline><highlight class="normal">42:<sp/><sp/><sp/>},<sp/>0);</highlight></codeline>
<codeline><highlight class="normal">43:</highlight></codeline>
<codeline><highlight class="normal">44:<sp/><sp/><sp/>executor.<ref refid="classtf_1_1Executor_1a81f35d5b0a20ac0646447eb80d97c0aa" kindref="member">run</ref>(taskflow).wait();</highlight></codeline>
<codeline><highlight class="normal">45:</highlight></codeline>
<codeline><highlight class="normal">46:<sp/><sp/><sp/>cudaFree(dx);</highlight></codeline>
<codeline><highlight class="normal">47:<sp/><sp/><sp/>cudaFree(dy);</highlight></codeline>
<codeline><highlight class="normal">48:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">49:<sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>verify<sp/>the<sp/>solution;<sp/>max_error<sp/>should<sp/>be<sp/>zero</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">50:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>max_error<sp/>=<sp/>0;</highlight></codeline>
<codeline><highlight class="normal">51:<sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>N;<sp/>i++)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">52:<sp/><sp/><sp/><sp/><sp/>max_error<sp/>=<sp/><ref refid="cpp/algorithm/max" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::max</ref>(max_error,<sp/>abs(z1[i]-4));</highlight></codeline>
<codeline><highlight class="normal">53:<sp/><sp/><sp/><sp/><sp/>max_error<sp/>=<sp/><ref refid="cpp/algorithm/max" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::max</ref>(max_error,<sp/>abs(z2[i]-4));</highlight></codeline>
<codeline><highlight class="normal">54:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal">55:<sp/><sp/><sp/><ref refid="cpp/io/basic_ostream" kindref="compound" external="/Users/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::cout</ref><sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;saxpy<sp/>finished<sp/>with<sp/>max<sp/>error:<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>max_error<sp/>&lt;&lt;<sp/></highlight><highlight class="charliteral">&apos;\n&apos;</highlight><highlight class="normal">;</highlight></codeline>
<codeline><highlight class="normal">56:<sp/>}</highlight></codeline>
</programlisting></para>
<para>Debrief:</para>
<para><itemizedlist>
<listitem><para>Lines 3-9 define a CUDA saxpy kernel that stores the result to <computeroutput>z</computeroutput> </para>
</listitem>
<listitem><para>Lines 15-23 declare four unified memory blocks accessible from any processor </para>
</listitem>
<listitem><para>Lines 25-28 initialize <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> blocks by CPU </para>
</listitem>
<listitem><para>Lines 33-42 create a cudaFlow task on GPU <computeroutput>0</computeroutput> using <ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">tf::Taskflow::emplace_on</ref> </para>
</listitem>
<listitem><para>Lines 37-38 create a kernel task to launch the first saxpy on GPU <computeroutput>1</computeroutput> and store the result in <computeroutput>z1</computeroutput> </para>
</listitem>
<listitem><para>Lines 40-41 create a kernel task to launch the second saxpy on GPU <computeroutput>3</computeroutput> and store the result in <computeroutput>z2</computeroutput> </para>
</listitem>
<listitem><para>Lines 44-55 run the taskflow and verify the result (<computeroutput>max_error</computeroutput> should be zero)</para>
</listitem>
</itemizedlist>
Running the program gives the following <ulink url="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvidia-smi</ulink> snapshot in a system of 4 GPUs:</para>
<para><programlisting filename=".shell-session"><codeline><highlight class="normal">+-----------------------------------------------------------------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/>NVIDIA-SMI<sp/>430.50<sp/><sp/><sp/><sp/><sp/><sp/><sp/>Driver<sp/>Version:<sp/>430.50<sp/><sp/><sp/><sp/><sp/><sp/><sp/>CUDA<sp/>Version:<sp/>10.1<sp/><sp/><sp/><sp/><sp/>|</highlight></codeline>
<codeline><highlight class="normal">|-------------------------------+----------------------+----------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/>GPU<sp/><sp/>Name<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Persistence-M|<sp/>Bus-Id<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Disp.A<sp/>|<sp/>Volatile<sp/>Uncorr.<sp/>ECC<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Fan<sp/><sp/>Temp<sp/><sp/>Perf<sp/><sp/>Pwr:Usage/Cap|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Memory-Usage<sp/>|<sp/>GPU-Util<sp/><sp/>Compute<sp/>M.<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|===============================+======================+======================|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/>0<sp/><sp/>GeForce<sp/>RTX<sp/>208...<sp/><sp/>Off<sp/><sp/>|<sp/>00000000:18:00.0<sp/>Off<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>N/A<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>32%<sp/><sp/><sp/>35C<sp/><sp/><sp/><sp/>P2<sp/><sp/><sp/><sp/>68W<sp/>/<sp/>250W<sp/>|<sp/><sp/><sp/><sp/>163MiB<sp/>/<sp/>11019MiB<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/>0%<sp/><sp/><sp/><sp/><sp/><sp/>Default<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-------------------------------+----------------------+----------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/>1<sp/><sp/>GeForce<sp/>RTX<sp/>208...<sp/><sp/>Off<sp/><sp/>|<sp/>00000000:3B:00.0<sp/>Off<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>N/A<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>33%<sp/><sp/><sp/>43C<sp/><sp/><sp/><sp/>P2<sp/><sp/><sp/>247W<sp/>/<sp/>250W<sp/>|<sp/><sp/><sp/><sp/>293MiB<sp/>/<sp/>11019MiB<sp/>|<sp/><sp/><sp/><sp/>100%<sp/><sp/><sp/><sp/><sp/><sp/>Default<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-------------------------------+----------------------+----------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/>2<sp/><sp/>GeForce<sp/>RTX<sp/>208...<sp/><sp/>Off<sp/><sp/>|<sp/>00000000:86:00.0<sp/>Off<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>N/A<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>32%<sp/><sp/><sp/>37C<sp/><sp/><sp/><sp/>P0<sp/><sp/><sp/><sp/>72W<sp/>/<sp/>250W<sp/>|<sp/><sp/><sp/><sp/><sp/>10MiB<sp/>/<sp/>11019MiB<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/>0%<sp/><sp/><sp/><sp/><sp/><sp/>Default<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-------------------------------+----------------------+----------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/>3<sp/><sp/>GeForce<sp/>RTX<sp/>208...<sp/><sp/>Off<sp/><sp/>|<sp/>00000000:AF:00.0<sp/>Off<sp/>|<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>N/A<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/>31%<sp/><sp/><sp/>43C<sp/><sp/><sp/><sp/>P2<sp/><sp/><sp/>245W<sp/>/<sp/>250W<sp/>|<sp/><sp/><sp/><sp/>293MiB<sp/>/<sp/>11019MiB<sp/>|<sp/><sp/><sp/><sp/>100%<sp/><sp/><sp/><sp/><sp/><sp/>Default<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-------------------------------+----------------------+----------------------+</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">+-----------------------------------------------------------------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Processes:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>GPU<sp/>Memory<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/>GPU<sp/><sp/><sp/><sp/><sp/><sp/><sp/>PID<sp/><sp/><sp/>Type<sp/><sp/><sp/>Process<sp/>name<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Usage<sp/><sp/><sp/><sp/><sp/><sp/>|</highlight></codeline>
<codeline><highlight class="normal">|=============================================================================|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>0<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>153MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>1<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>155MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>3<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>155MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-----------------------------------------------------------------------------+</highlight></codeline>
</programlisting></para>
<para><simplesect kind="attention"><para>tf::emplace_on allows you to place a cudaFlow on a particular GPU device, but it is your responsibility to ensure correct memory access. For example, you may not allocate a memory block on GPU <computeroutput>2</computeroutput> using <computeroutput>cudaMalloc</computeroutput> and access it from a kernel on GPU <computeroutput>1</computeroutput>.</para>
</simplesect>
An easy practice is to allocate <emphasis>unified shared memory</emphasis> using <computeroutput>cudaMallocManaged</computeroutput> and let the CUDA runtime perform automatic memory migration between processors (as demonstrated in the code example above).</para>
<para>As the same example, you may create two cudaFlows for the two kernels on two GPUs, respectively. The overhead of creating a kernel on the same device as a cudaFlow is much less than the different one.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaFlow_on_gpu1<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z1);</highlight></codeline>
<codeline><highlight class="normal">},<sp/>1);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaFlow_on_gpu3<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z2);</highlight></codeline>
<codeline><highlight class="normal">},<sp/>3);</highlight></codeline>
</programlisting></para>
</sect1>
<sect1 id="chapter6_1C6_GPUMemoryOperations">
<title>Access GPU Memory</title>
<para><ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> provides a set of methods for users to manipulate device memory data. There are two categories, raw data and typed data. Raw data operations are methods with prefix <computeroutput>mem</computeroutput>, such as <computeroutput>memcpy</computeroutput> and <computeroutput>memset</computeroutput>, that take action on GPU memory area in <emphasis>bytes</emphasis>. Typed data operations such as <computeroutput>copy</computeroutput>, <computeroutput>fill</computeroutput>, and <computeroutput>zero</computeroutput>, take <emphasis>logical count</emphasis> of elements. For instance, the following three methods have the same result of zeroing <computeroutput>sizeof(int)*count</computeroutput> bytes of the device memory area pointed to by <computeroutput>target</computeroutput>.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="keywordtype">int</highlight><highlight class="normal">*<sp/>target;</highlight></codeline>
<codeline><highlight class="normal">cudaMalloc(&amp;target,<sp/>count*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">));</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>memset_target<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a079ca65da35301e5aafd45878a19e9d2" kindref="member">memset</ref>(target,<sp/>0,<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)<sp/>*<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">fill</ref>(target,<sp/>0,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above_again<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a40172fac4464f6d805f75921ea3c2a3b" kindref="member">zero</ref>(target,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para>
<para>The method <ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">cudaFlow::fill</ref> is a more powerful version of <ref refid="classtf_1_1cudaFlow_1a079ca65da35301e5aafd45878a19e9d2" kindref="member">cudaFlow::memset</ref>. It can fill a memory area with any value of type <computeroutput>T</computeroutput>, given that <computeroutput>sizeof(T)</computeroutput> is 1, 2, or 4 bytes. For example, the following code sets each element in the array <computeroutput>target</computeroutput> to 1234.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">fill</ref>(target,<sp/>1234,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para>
<para>Similar concept applies to <ref refid="classtf_1_1cudaFlow_1ad37637606f0643f360e9eda1f9a6e559" kindref="member">cudaFlow::memcpy</ref> and <ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">cudaFlow::copy</ref> as well.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>memcpy_target<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1ad37637606f0643f360e9eda1f9a6e559" kindref="member">memcpy</ref>(target,<sp/>source,<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)<sp/>*<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(target,<sp/>source,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para>
</sect1>
<sect1 id="chapter6_1C6_Granularity">
<title>Study the Granularity</title>
<para>Creating a cudaFlow has certain overhead, which means fined-grained tasking such as one GPU operation per cudaFlow may not give you any performance gain. You should aggregate as many GPU operations as possible in a cudaFlow to launch the entire graph once instead of separate calls. For example, the following code creates the saxpy task graph at a very fine-grained level using one cudaFlow per GPU operation.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>h2d_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>h2d_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>d2h_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>d2h_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>kernel<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy).name(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;kernel&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">kernel.<ref refid="classtf_1_1Task_1a331b1b726555072e7c7d10941257f664" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1Task_1a8c78c453295a553c1c016e4062da8588" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
</programlisting></para>
<para><dotfile name="/Users/twhuang/Code/taskflow/doxygen/images/saxpy_5_cudaflow.dot"></dotfile>
</para>
<para>The following code aggregates the five GPU operations using one cudaFlow and achieves better performance.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaflow<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>saxpy<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>saxpy.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para>
<para><dotfile name="/Users/twhuang/Code/taskflow/doxygen/images/saxpy_1_cudaflow.dot"></dotfile>
</para>
<para><simplesect kind="note"><para>We encourage users to study and understand the parallel structure of their applications, in order to come up with the best granularity of task decomposition. A refined task graph can have significant performance difference from the raw counterpart.</para>
</simplesect>
</para>
</sect1>
<sect1 id="chapter6_1C6_OffloadAndUpdateAcudaFlow">
<title>Offload and Update a cudaFlow</title>
<para>Many GPU applications require you to launch a cudaFlow mutiple times and update node parameters (e.g., kernel parameters and memory addresses) between iterations. <ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">tf::cudaFlow::offload</ref> allows you to execute the graph immediately and then update the parameters for the next execution. When you offload a cudaFlow, an executable graph will be created, and you must NOT change the topology but the node parameters between successive executions.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><sp/>1:<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;]<sp/>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>2:<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/>3:<sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>task<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(grid1,<sp/>block1,<sp/>shm1,<sp/>my_kernel,<sp/>args1...);</highlight></codeline>
<codeline><highlight class="normal"><sp/>4:</highlight></codeline>
<codeline><highlight class="normal"><sp/>5:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>immediately<sp/>run<sp/>the<sp/>cudaFlow<sp/>once</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/>6:</highlight></codeline>
<codeline><highlight class="normal"><sp/>7:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1aa841b36aca935162489b5e7430dafe99" kindref="member">update_kernel</ref>(task,<sp/>grid2,<sp/>block2,<sp/>shm2,<sp/>args2...);</highlight></codeline>
<codeline><highlight class="normal"><sp/>8:</highlight></codeline>
<codeline><highlight class="normal"><sp/>9:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>run<sp/>the<sp/>cudaFlow<sp/>of<sp/>the<sp/>same<sp/>topology<sp/>again</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">10:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>but<sp/>with<sp/>different<sp/>kernel<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">11:<sp/>});</highlight></codeline>
</programlisting></para>
<para>Debrief:<itemizedlist>
<listitem><para>Line 3 creates a kernel task to run <computeroutput>my_kernel</computeroutput> with the given parameters</para>
</listitem><listitem><para>Line 5 offloads the cudaFlow and performs an immediate execution; afterwards, we must not modify the graph topology</para>
</listitem><listitem><para>Line 7 updates the parameters of <computeroutput>my_kernel</computeroutput> associated with <computeroutput>task</computeroutput> </para>
</listitem><listitem><para>Line 9 executes the cudaFlow again with updated kernel parameters</para>
</listitem></itemizedlist>
</para>
<para>We currently supports the following offload methods:<itemizedlist>
<listitem><para><ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">tf::cudaFlow::offload</ref> offloads and runs the cudaFlow once</para>
</listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1ac2269fd7dc8ca04a294a718204703dad" kindref="member">tf::cudaFlow::offload_n</ref> offloads and runs the cudaFlow <computeroutput>n</computeroutput> times</para>
</listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a99358da15e3bdfa1faabb3e326130e1f" kindref="member">tf::cudaFlow::offload_until</ref> offloads and keeps running the cudaFlow until the given predicate returns <computeroutput>true</computeroutput> </para>
</listitem></itemizedlist>
</para>
<para><simplesect kind="note"><para>The executor will not run an offloaded cudaFlow after the task callable. By default, the executor runs the cudaFlow once if it hasn&apos;t been offloaded from the callable.</para>
</simplesect>
</para>
</sect1>
<sect1 id="chapter6_1C6_UsecudaFlowInAStandaloneEnvironment">
<title>Use cudaFlow in a Standalone Environment</title>
<para>You can use <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> in a standalone environment without going through <ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref> and offloads it to GPU from the caller thread. All the features we have discussed so far are applicable for the standalone use.</para>
<para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref><sp/>cf;<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>a<sp/>standalone<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>saxpy<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">saxpy.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)<sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>kernel<sp/>runs<sp/>after<sp/><sp/>host-to-device<sp/>copy</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);<sp/><sp/></highlight><highlight class="comment">//<sp/>kernel<sp/>runs<sp/>before<sp/>device-to-host<sp/>copy</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>offload<sp/>and<sp/>runs<sp/>the<sp/>standalone<sp/>cudaFlow<sp/>once</highlight></codeline>
</programlisting></para>
<para><simplesect kind="attention"><para>When using cudaFlow in a standalone environment, it is your choice and responsibility to decide its GPU context and ensure that GPU memory operations are correctly performed. </para>
</simplesect>
</para>
</sect1>
    </detaileddescription>
  </compounddef>
</doxygen>
