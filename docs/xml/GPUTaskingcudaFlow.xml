<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.8.14">
  <compounddef id="GPUTaskingcudaFlow" kind="page">
    <compoundname>GPUTaskingcudaFlow</compoundname>
    <title>GPU Tasking (cudaFlow)</title>
    <tableofcontents/>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para>Modern scientific computing typically leverages GPU-powered parallel processing cores to speed up large-scale applications. This chapter discusses how to implement CPU-GPU heterogeneous tasking algorithms with <ulink url="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</ulink>.</para><sect1 id="GPUTaskingcudaFlow_1C6_Create_a_cudaFlow">
<title>Create a cudaFlow</title>
<para>Taskflow enables concurrent CPU-GPU tasking by leveraging <ulink url="https://developer.nvidia.com/blog/cuda-graphs/">CUDA Graph</ulink>. The tasking interface is referred to as <emphasis>cudaFlow</emphasis>. A cudaFlow is a graph object of type <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> created at runtime similar to dynamic tasking. It manages a task node in a taskflow and associates it with a CUDA Graph. To create a cudaFlow, emplace a callable with an argument of type <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>. The following example implements the canonical saxpy (A·X Plus Y) task graph.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><sp/>1:<sp/>#include<sp/>&lt;taskflow/cudaflow.hpp&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/>2:<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/>3:<sp/></highlight><highlight class="comment">//<sp/>saxpy<sp/>(single-precision<sp/>A·X<sp/>Plus<sp/>Y)<sp/>kernel</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/>4:<sp/>__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>saxpy(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>a,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>5:<sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>blockIdx.x*blockDim.x<sp/>+<sp/>threadIdx.x;</highlight></codeline>
<codeline><highlight class="normal"><sp/>6:<sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i<sp/>&lt;<sp/>n)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>7:<sp/><sp/><sp/><sp/><sp/>y[i]<sp/>=<sp/>a*x[i]<sp/>+<sp/>y[i];</highlight></codeline>
<codeline><highlight class="normal"><sp/>8:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/>9:<sp/>}</highlight></codeline>
<codeline><highlight class="normal">10:</highlight></codeline>
<codeline><highlight class="normal">11:<sp/></highlight><highlight class="comment">//<sp/>main<sp/>function<sp/>begins</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">12:<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>main()<sp/>{</highlight></codeline>
<codeline><highlight class="normal">13:</highlight></codeline>
<codeline><highlight class="normal">14:<sp/><sp/><sp/><ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref><sp/>taskflow;</highlight></codeline>
<codeline><highlight class="normal">15:<sp/><sp/><sp/><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor;</highlight></codeline>
<codeline><highlight class="normal">16:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">17:<sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>N<sp/>=<sp/>1&lt;&lt;20;<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>size<sp/>of<sp/>the<sp/>vector</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">18:</highlight></codeline>
<codeline><highlight class="normal">19:<sp/><sp/><sp/><ref refid="cpp/container/vector" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::vector&lt;float&gt;</ref><sp/>hx(N,<sp/>1.0f);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>x<sp/>vector<sp/>at<sp/>host</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">20:<sp/><sp/><sp/><ref refid="cpp/container/vector" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::vector&lt;float&gt;</ref><sp/>hy(N,<sp/>2.0f);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>y<sp/>vector<sp/>at<sp/>host</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">21:</highlight></codeline>
<codeline><highlight class="normal">22:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dx{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>x<sp/>vector<sp/>at<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">23:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*dy{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>y<sp/>vector<sp/>at<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">24:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">25:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>allocate_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(</highlight></codeline>
<codeline><highlight class="normal">26:<sp/><sp/><sp/><sp/><sp/>[&amp;](){<sp/>cudaMalloc(&amp;dx,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));}</highlight></codeline>
<codeline><highlight class="normal">27:<sp/><sp/><sp/>).name(</highlight><highlight class="stringliteral">&quot;allocate_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">28:</highlight></codeline>
<codeline><highlight class="normal">29:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>allocate_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(</highlight></codeline>
<codeline><highlight class="normal">30:<sp/><sp/><sp/><sp/><sp/>[&amp;](){<sp/>cudaMalloc(&amp;dy,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));}</highlight></codeline>
<codeline><highlight class="normal">31:<sp/><sp/><sp/>).name(</highlight><highlight class="stringliteral">&quot;allocate_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">32:</highlight></codeline>
<codeline><highlight class="normal">33:<sp/><sp/><sp/><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaflow<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">34:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>data<sp/>transfer<sp/>tasks</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">35:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);<sp/></highlight></codeline>
<codeline><highlight class="normal">36:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">37:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">38:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">39:</highlight></codeline>
<codeline><highlight class="normal">40:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>saxpy&lt;&lt;&lt;(N+255)/256,<sp/>256,<sp/>0&gt;&gt;&gt;(N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">41:<sp/><sp/><sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>kernel<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(</highlight></codeline>
<codeline><highlight class="normal">42:<sp/><sp/><sp/><sp/><sp/><sp/><sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy</highlight></codeline>
<codeline><highlight class="normal">43:<sp/><sp/><sp/><sp/><sp/>).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">44:</highlight></codeline>
<codeline><highlight class="normal">45:<sp/><sp/><sp/><sp/><sp/>kernel.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal">46:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
<codeline><highlight class="normal">48:<sp/><sp/><sp/>}).name(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">49:<sp/><sp/><sp/>cudaflow.<ref refid="classtf_1_1Task_1a331b1b726555072e7c7d10941257f664" kindref="member">succeed</ref>(allocate_x,<sp/>allocate_y);<sp/><sp/></highlight><highlight class="comment">//<sp/>overlap<sp/>memory<sp/>alloc</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">50:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">51:<sp/><sp/><sp/>executor.<ref refid="classtf_1_1Executor_1a519777f5783981d534e9e53b99712069" kindref="member">run</ref>(taskflow).wait();</highlight></codeline>
<codeline><highlight class="normal">52:</highlight></codeline>
<codeline><highlight class="normal">53:<sp/><sp/><sp/>taskflow.<ref refid="classtf_1_1Taskflow_1ac433018262e44b12c4cc9f0c4748d758" kindref="member">dump</ref>(<ref refid="cpp/io/basic_ostream" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::cout</ref>);<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>dump<sp/>the<sp/>taskflow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">54:<sp/>}</highlight></codeline>
</programlisting></para><para><dotfile name="/home/twhuang/Code/taskflow/doxygen/images/saxpy.dot"></dotfile>
</para><para>Debrief:</para><para><itemizedlist>
<listitem><para>Lines 3-9 define a saxpy kernel using CUDA </para></listitem>
<listitem><para>Lines 19-20 declare two host vectors, <computeroutput>hx</computeroutput> and <computeroutput>hy</computeroutput> </para></listitem>
<listitem><para>Lines 22-23 declare two device vector pointers, <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> </para></listitem>
<listitem><para>Lines 25-31 declare two tasks to allocate memory for <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> on device, each of <computeroutput>N*sizeof(float)</computeroutput> bytes </para></listitem>
<listitem><para>Lines 33-48 create a cudaFlow to define a GPU task graph (two host-to-device data transfer tasks, one saxpy kernel task, and two device-to-host data transfer tasks) </para></listitem>
<listitem><para>Lines 49-53 define the task dependency between host tasks and the cudaFlow tasks and execute the taskflow</para></listitem>
</itemizedlist>
Taskflow does not expend unnecessary efforts on kernel programming but focus on tasking CUDA operations with CPU work. We give users full privileges to craft a CUDA kernel that is commensurate with their domain knowledge. Users focus on developing high-performance kernels using a native CUDA toolkit, while leaving difficult task parallelism to Taskflow.</para><para><simplesect kind="attention"><para>You need to include <computeroutput><ref refid="cudaflow_8hpp" kindref="compound">taskflow/cudaflow.hpp</ref></computeroutput> in order to use <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>.</para></simplesect>
</para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_Compile_a_cudaFlow_program">
<title>Compile a cudaFlow Program</title>
<para>Use <ulink url="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</ulink> (at least v11.1) to compile a cudaFlow program:</para><para><programlisting filename=".shell-session"><codeline><highlight class="normal">~$<sp/>nvcc<sp/>-std=c++17<sp/>my_cudaflow.cu<sp/>-I<sp/>path/to/include/taskflow<sp/>-O2<sp/>-o<sp/>my_cudaflow</highlight></codeline>
<codeline><highlight class="normal">~$<sp/>./my_cudaflow</highlight></codeline>
</programlisting></para><para>Please visit the page <ref refid="CompileTaskflowWithCUDA" kindref="compound">Compile Taskflow with CUDA</ref> for more details.</para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_run_a_cudaflow_on_multiple_gpus">
<title>Run a cudaFlow on Multiple GPUs</title>
<para>By default, a cudaFlow runs on the current GPU associated with the caller, which is typically <computeroutput>0</computeroutput>. You can run a cudaFlow on multiple GPUs by explicitly associating a cudaFlow or a kernel task with a CUDA device. A CUDA device is an integer number in the range of <computeroutput>[0, N)</computeroutput> representing the identifier of a GPU, where <computeroutput>N</computeroutput> is the number of GPUs in a system. The code below creates a cudaFlow that runs on GPU <computeroutput>0</computeroutput>.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([]<sp/>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{},<sp/>0);<sp/><sp/></highlight><highlight class="comment">//<sp/>place<sp/>the<sp/>cudaFlow<sp/>on<sp/>GPU<sp/>0</highlight></codeline>
</programlisting></para><para>You can place a kernel on a GPU explicitly through the method <ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">tf::cudaFlow::kernel_on</ref> that takes the GPU device identifier in the first argument.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><sp/>1:<sp/>#include<sp/>&lt;taskflow/cudaflow.hpp&gt;</highlight></codeline>
<codeline><highlight class="normal"><sp/>2:<sp/></highlight></codeline>
<codeline><highlight class="normal"><sp/>3:<sp/></highlight><highlight class="comment">//<sp/>saxpy<sp/>(single-precision<sp/>A·X<sp/>Plus<sp/>Y)<sp/>kernel</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/>4:<sp/>__global__<sp/></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/>saxpy(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>n,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>a,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*x,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*y,<sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>*z)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>5:<sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>blockIdx.x*blockDim.x<sp/>+<sp/>threadIdx.x;</highlight></codeline>
<codeline><highlight class="normal"><sp/>6:<sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(i<sp/>&lt;<sp/>n)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/>7:<sp/><sp/><sp/><sp/>z[i]<sp/>=<sp/>a*x[i]<sp/>+<sp/>y[i];</highlight></codeline>
<codeline><highlight class="normal"><sp/>8:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal"><sp/>9:<sp/>}</highlight></codeline>
<codeline><highlight class="normal">10:</highlight></codeline>
<codeline><highlight class="normal">11:<sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>main()<sp/>{</highlight></codeline>
<codeline><highlight class="normal">12:</highlight></codeline>
<codeline><highlight class="normal">13:<sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>N<sp/>=<sp/>1&lt;&lt;20;</highlight></codeline>
<codeline><highlight class="normal">14:<sp/><sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">15:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>dx<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">16:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>dy<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">17:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>z1<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">18:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal">*<sp/>z2<sp/>{</highlight><highlight class="keyword">nullptr</highlight><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal">19:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">20:<sp/><sp/><sp/>cudaMallocManaged(&amp;dx,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>unified<sp/>memory<sp/>for<sp/>x</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">21:<sp/><sp/><sp/>cudaMallocManaged(&amp;dy,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>unified<sp/>memory<sp/>for<sp/>y</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">22:<sp/><sp/><sp/>cudaMallocManaged(&amp;z1,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>result<sp/>of<sp/>saxpy<sp/>task<sp/>1</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">23:<sp/><sp/><sp/>cudaMallocManaged(&amp;z2,<sp/>N*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">float</highlight><highlight class="normal">));<sp/><sp/></highlight><highlight class="comment">//<sp/>result<sp/>of<sp/>saxpy<sp/>task<sp/>2</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">24:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">25:<sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">unsigned</highlight><highlight class="normal"><sp/>i=0;<sp/>i&lt;N;<sp/>++i)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">26:<sp/><sp/><sp/><sp/><sp/>dx[i]<sp/>=<sp/>1;</highlight></codeline>
<codeline><highlight class="normal">27:<sp/><sp/><sp/><sp/><sp/>dy[i]<sp/>=<sp/>2;</highlight></codeline>
<codeline><highlight class="normal">28:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal">29:</highlight></codeline>
<codeline><highlight class="normal">30:<sp/><sp/><sp/><ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref><sp/>taskflow;</highlight></codeline>
<codeline><highlight class="normal">31:<sp/><sp/><sp/><ref refid="classtf_1_1Executor" kindref="compound">tf::Executor</ref><sp/>executor;</highlight></codeline>
<codeline><highlight class="normal">32:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">33:<sp/><sp/><sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal">34:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>create<sp/>a<sp/>cudaFlow<sp/>on<sp/>GPU<sp/>0.<sp/>The<sp/>scheduler<sp/>will<sp/>switch<sp/>to<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">35:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>GPU<sp/>context<sp/>0<sp/>when<sp/>running<sp/>this<sp/>callable.</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">36:</highlight></codeline>
<codeline><highlight class="normal">37:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>the<sp/>first<sp/>saxpy<sp/>kernel<sp/>on<sp/>GPU<sp/>1</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">38:<sp/><sp/><sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">kernel_on</ref>(1,<sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z1).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;1&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">39:</highlight></codeline>
<codeline><highlight class="normal">40:<sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>launch<sp/>the<sp/>second<sp/>saxpy<sp/>kernel<sp/>on<sp/>GPU<sp/>3</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">41:<sp/><sp/><sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a4a839dbaa01237a440edfebe8faf4e5b" kindref="member">kernel_on</ref>(3,<sp/>(N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z2).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;3&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">42:<sp/><sp/><sp/>},<sp/>0).name(</highlight><highlight class="stringliteral">&quot;cudaFlow<sp/>on<sp/>GPU<sp/>0&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">43:</highlight></codeline>
<codeline><highlight class="normal">44:<sp/><sp/><sp/>executor.<ref refid="classtf_1_1Executor_1a519777f5783981d534e9e53b99712069" kindref="member">run</ref>(taskflow).wait();</highlight></codeline>
<codeline><highlight class="normal">45:</highlight></codeline>
<codeline><highlight class="normal">46:<sp/><sp/><sp/>cudaFree(dx);</highlight></codeline>
<codeline><highlight class="normal">47:<sp/><sp/><sp/>cudaFree(dy);</highlight></codeline>
<codeline><highlight class="normal">48:<sp/><sp/></highlight></codeline>
<codeline><highlight class="normal">49:<sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>verify<sp/>the<sp/>solution;<sp/>max_error<sp/>should<sp/>be<sp/>zero</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">50:<sp/><sp/><sp/></highlight><highlight class="keywordtype">float</highlight><highlight class="normal"><sp/>max_error<sp/>=<sp/>0;</highlight></codeline>
<codeline><highlight class="normal">51:<sp/><sp/><sp/></highlight><highlight class="keywordflow">for</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>i<sp/>=<sp/>0;<sp/>i<sp/>&lt;<sp/>N;<sp/>i++)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">52:<sp/><sp/><sp/><sp/><sp/>max_error<sp/>=<sp/><ref refid="cpp/algorithm/max" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::max</ref>(max_error,<sp/>abs(z1[i]-4));</highlight></codeline>
<codeline><highlight class="normal">53:<sp/><sp/><sp/><sp/><sp/>max_error<sp/>=<sp/><ref refid="cpp/algorithm/max" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::max</ref>(max_error,<sp/>abs(z2[i]-4));</highlight></codeline>
<codeline><highlight class="normal">54:<sp/><sp/><sp/>}</highlight></codeline>
<codeline><highlight class="normal">55:<sp/><sp/><sp/><ref refid="cpp/io/basic_ostream" kindref="compound" external="/home/twhuang/Code/taskflow/doxygen/cppreference-doxygen-web.tag.xml">std::cout</ref><sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;saxpy<sp/>finished<sp/>with<sp/>max<sp/>error:<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>max_error<sp/>&lt;&lt;<sp/></highlight><highlight class="charliteral">&apos;\n&apos;</highlight><highlight class="normal">;</highlight></codeline>
<codeline><highlight class="normal">56:<sp/>}</highlight></codeline>
</programlisting></para><para>Debrief:</para><para><itemizedlist>
<listitem><para>Lines 3-9 define a CUDA saxpy kernel that stores the result to <computeroutput>z</computeroutput> </para></listitem>
<listitem><para>Lines 15-23 declare four unified memory blocks accessible from any processor </para></listitem>
<listitem><para>Lines 25-28 initialize <computeroutput>dx</computeroutput> and <computeroutput>dy</computeroutput> blocks by CPU </para></listitem>
<listitem><para>Lines 33-42 create a cudaFlow task on GPU <computeroutput>0</computeroutput> using <ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">tf::Taskflow::emplace_on</ref> </para></listitem>
<listitem><para>Lines 37-38 create a kernel task to launch the first saxpy on GPU <computeroutput>1</computeroutput> and store the result in <computeroutput>z1</computeroutput> </para></listitem>
<listitem><para>Lines 40-41 create a kernel task to launch the second saxpy on GPU <computeroutput>3</computeroutput> and store the result in <computeroutput>z2</computeroutput> </para></listitem>
<listitem><para>Lines 44-55 run the taskflow and verify the result (<computeroutput>max_error</computeroutput> should be zero)</para></listitem>
</itemizedlist>
Running the program gives the following <ulink url="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvidia-smi</ulink> snapshot in a system of 4 GPUs:</para><para><programlisting filename=".shell-session"><codeline><highlight class="normal">+-----------------------------------------------------------------------------+</highlight></codeline>
<codeline><highlight class="normal">|<sp/>Processes:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>GPU<sp/>Memory<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/>GPU<sp/><sp/><sp/><sp/><sp/><sp/><sp/>PID<sp/><sp/><sp/>Type<sp/><sp/><sp/>Process<sp/>name<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>Usage<sp/><sp/><sp/><sp/><sp/><sp/>|</highlight></codeline>
<codeline><highlight class="normal">|=============================================================================|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>0<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>153MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>1<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>155MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">|<sp/><sp/><sp/><sp/>3<sp/><sp/><sp/><sp/><sp/>53869<sp/><sp/><sp/><sp/><sp/><sp/>C<sp/><sp/><sp/>./a.out<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>155MiB<sp/>|</highlight></codeline>
<codeline><highlight class="normal">+-----------------------------------------------------------------------------+</highlight></codeline>
</programlisting></para><para><simplesect kind="attention"><para><ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">tf::Taskflow::emplace_on</ref> allows you to place a cudaFlow on a particular GPU device, but it is your responsibility to ensure correct memory access. For example, you may not allocate a memory block on GPU <computeroutput>2</computeroutput> using <computeroutput>cudaMalloc</computeroutput> and access it from a kernel on GPU <computeroutput>1</computeroutput>.</para></simplesect>
An easy practice is to allocate <emphasis>unified shared memory</emphasis> using <computeroutput>cudaMallocManaged</computeroutput> and let the CUDA runtime perform automatic memory migration between processors (as demonstrated in the code example above).</para><para>As the same example, you may create two cudaFlows for the two kernels on two GPUs, respectively. The overhead of creating a kernel on the same device as a cudaFlow is much less than the different one.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaFlow_on_gpu1<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z1);</highlight></codeline>
<codeline><highlight class="normal">},<sp/>1);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaFlow_on_gpu3<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1afdf47fd1a358fb64f8c1b89e2a393169" kindref="member">emplace_on</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2,<sp/>dx,<sp/>dy,<sp/>z2);</highlight></codeline>
<codeline><highlight class="normal">},<sp/>3);</highlight></codeline>
</programlisting></para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_GPUMemoryOperations">
<title>Access GPU Memory</title>
<para><ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> provides a set of methods for users to manipulate device memory data. There are two categories, raw data and typed data. Raw data operations are methods with prefix <computeroutput>mem</computeroutput>, such as <computeroutput>memcpy</computeroutput> and <computeroutput>memset</computeroutput>, that take action on GPU memory area in <emphasis>bytes</emphasis>. Typed data operations such as <computeroutput>copy</computeroutput>, <computeroutput>fill</computeroutput>, and <computeroutput>zero</computeroutput>, take <emphasis>logical count</emphasis> of elements. For instance, the following three methods have the same result of zeroing <computeroutput>sizeof(int)*count</computeroutput> bytes of the device memory area pointed to by <computeroutput>target</computeroutput>.</para><para><programlisting filename=".cpp"><codeline><highlight class="keywordtype">int</highlight><highlight class="normal">*<sp/>target;</highlight></codeline>
<codeline><highlight class="normal">cudaMalloc(&amp;target,<sp/>count*</highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">));</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>memset_target<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a079ca65da35301e5aafd45878a19e9d2" kindref="member">memset</ref>(target,<sp/>0,<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)<sp/>*<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">fill</ref>(target,<sp/>0,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above_again<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a40172fac4464f6d805f75921ea3c2a3b" kindref="member">zero</ref>(target,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para><para>The method <ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">cudaFlow::fill</ref> is a more powerful version of <ref refid="classtf_1_1cudaFlow_1a079ca65da35301e5aafd45878a19e9d2" kindref="member">cudaFlow::memset</ref>. It can fill a memory area with any value of type <computeroutput>T</computeroutput>, given that <computeroutput>sizeof(T)</computeroutput> is 1, 2, or 4 bytes. For example, the following code sets each element in the array <computeroutput>target</computeroutput> to 1234.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){<sp/>cf.<ref refid="classtf_1_1cudaFlow_1a21d4447bc834f4d3e1bb4772c850d090" kindref="member">fill</ref>(target,<sp/>1234,<sp/>count);<sp/>});</highlight></codeline>
</programlisting></para><para>Similar concept applies to <ref refid="classtf_1_1cudaFlow_1ad37637606f0643f360e9eda1f9a6e559" kindref="member">cudaFlow::memcpy</ref> and <ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">cudaFlow::copy</ref> as well.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf){</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>memcpy_target<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1ad37637606f0643f360e9eda1f9a6e559" kindref="member">memcpy</ref>(target,<sp/>source,<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">int</highlight><highlight class="normal">)<sp/>*<sp/>count);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>same_as_above<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(target,<sp/>source,<sp/>count);</highlight></codeline>
<codeline><highlight class="normal">});</highlight></codeline>
</programlisting></para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_Granularity">
<title>Study the Granularity</title>
<para>Creating a cudaFlow has certain overhead, which means fined-grained tasking such as one GPU operation per cudaFlow may not give you any performance gain. You should aggregate as many GPU operations as possible in a cudaFlow to launch the entire graph once instead of separate calls. For example, the following code creates the saxpy task graph at a very fine-grained level using one cudaFlow per GPU operation.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>h2d_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);<sp/><sp/></highlight><highlight class="comment">//<sp/>creates<sp/>the<sp/>1st<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>h2d_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);<sp/><sp/></highlight><highlight class="comment">//<sp/>creates<sp/>the<sp/>2nd<sp/>cudaFlow<sp/></highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>d2h_x<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);<sp/><sp/></highlight><highlight class="comment">//<sp/>creates<sp/>the<sp/>3rd<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>d2h_y<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);<sp/><sp/></highlight><highlight class="comment">//<sp/>creates<sp/>the<sp/>4th<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>kernel<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;kernel&quot;</highlight><highlight class="normal">);<sp/></highlight><highlight class="comment">//<sp/>creates<sp/>the<sp/>5th<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">kernel.<ref refid="classtf_1_1Task_1a331b1b726555072e7c7d10941257f664" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1Task_1a8c78c453295a553c1c016e4062da8588" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
</programlisting></para><para><dotfile name="/home/twhuang/Code/taskflow/doxygen/images/saxpy_5_cudaflow.dot"></dotfile>
</para><para>The following code aggregates the five GPU operations using one cudaFlow and achieves better performance.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1Task" kindref="compound">tf::Task</ref><sp/>cudaflow<sp/>=<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;](<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>saxpy<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>saxpy.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);</highlight></codeline>
<codeline><highlight class="normal">}).name(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);<sp/><sp/></highlight><highlight class="comment">//<sp/>creates<sp/>one<sp/>cudaFlow</highlight></codeline>
</programlisting></para><para><dotfile name="/home/twhuang/Code/taskflow/doxygen/images/saxpy_1_cudaflow.dot"></dotfile>
</para><para><simplesect kind="note"><para>We encourage users to study and understand the parallel structure of their applications, in order to come up with the best granularity of task decomposition. A refined task graph can have significant performance difference from the raw counterpart.</para></simplesect>
</para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_OffloadAndUpdateAcudaFlow">
<title>Offload and Update a cudaFlow</title>
<para>Many GPU applications require you to launch a cudaFlow mutiple times and update node parameters (e.g., kernel parameters and memory addresses) between iterations. <ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">tf::cudaFlow::offload</ref> allows you to execute the graph immediately and then update the parameters for the next execution. When you offload a cudaFlow, an executable graph will be created, and you must NOT change the topology but the node parameters between successive executions.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">1:<sp/>taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>([&amp;]<sp/>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal">2:<sp/><sp/><sp/><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>task<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(grid1,<sp/>block1,<sp/>shm1,<sp/>my_kernel,<sp/>args1...);</highlight></codeline>
<codeline><highlight class="normal">3:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>immediately<sp/>run<sp/>the<sp/>cudaFlow<sp/>once</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">4:</highlight></codeline>
<codeline><highlight class="normal">5:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1abab3a11129e6286c1de3deecedae8090" kindref="member">update_kernel</ref>(task,<sp/>grid2,<sp/>block2,<sp/>shm2,<sp/>args2...);</highlight></codeline>
<codeline><highlight class="normal">6:<sp/><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>run<sp/>the<sp/>cudaFlow<sp/>again<sp/>with<sp/>the<sp/>same<sp/>graph<sp/>topology</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">7:<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>but<sp/>with<sp/>different<sp/>kernel<sp/>parameters</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">8:<sp/>});</highlight></codeline>
</programlisting></para><para>Line 2 creates a kernel task to run <computeroutput>my_kernel</computeroutput> with the given parameters. Line 3 offloads the cudaFlow and performs an immediate execution; afterwards, we must not modify the graph topology. Line 5 updates the parameters of <computeroutput>my_kernel</computeroutput> associated with <computeroutput>task</computeroutput>. Line 6 executes the cudaFlow again with updated kernel parameters. We currently supports the following offload methods:<itemizedlist>
<listitem><para><ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">tf::cudaFlow::offload</ref> offloads and runs the cudaFlow once</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1ac2269fd7dc8ca04a294a718204703dad" kindref="member">tf::cudaFlow::offload_n</ref> offloads and runs the cudaFlow <computeroutput>n</computeroutput> times</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a99358da15e3bdfa1faabb3e326130e1f" kindref="member">tf::cudaFlow::offload_until</ref> offloads and keeps running the cudaFlow until the given predicate returns <computeroutput>true</computeroutput> </para></listitem></itemizedlist>
</para><para><programlisting filename=".cpp"><codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>...<sp/>create<sp/>CUDA<sp/>tasks</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>offload<sp/>the<sp/>cudaFlow<sp/>and<sp/>run<sp/>it<sp/>once</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1ac2269fd7dc8ca04a294a718204703dad" kindref="member">offload_n</ref>(10);<sp/><sp/></highlight><highlight class="comment">//<sp/>offload<sp/>the<sp/>cudaFlow<sp/>and<sp/>run<sp/>it<sp/>10<sp/>times</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a99358da15e3bdfa1faabb3e326130e1f" kindref="member">offload_until</ref>([repeat=5]<sp/>()<sp/></highlight><highlight class="keyword">mutable</highlight><highlight class="normal"><sp/>{<sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>repeat--<sp/>==<sp/>0;<sp/>})<sp/><sp/></highlight><highlight class="comment">//<sp/>5<sp/>times</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">};</highlight></codeline>
</programlisting></para><para>After you offload a cudaFlow (possibly multiple times), it is considered executed, and the executor will not run an offloaded cudaFlow after the cudaFlow task callable. On the other hand, if a cudaFlow is not offloaded, the executor runs it once. For example, the following two versions represent the same execution logic.</para><para><programlisting filename=".cpp"><codeline><highlight class="comment">//<sp/>version<sp/>1:<sp/>explicitly<sp/>offload<sp/>a<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(grid,<sp/>block,<sp/>shm,<sp/>my_kernel,<sp/>my_kernel_args).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;my_kernel&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();</highlight></codeline>
<codeline><highlight class="normal">};</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight><highlight class="comment">//<sp/>version<sp/>2<sp/>(same<sp/>as<sp/>version<sp/>1):<sp/>executor<sp/>offloads<sp/>the<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">taskflow.<ref refid="classtf_1_1FlowBuilder_1a60d7a666cab71ecfa3010b2efb0d6b57" kindref="member">emplace</ref>(<ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref>&amp;<sp/>cf)<sp/>{</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>(grid,<sp/>block,<sp/>shm,<sp/>my_kernel,<sp/>my_kernel_args).<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;my_kernel&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal">};</highlight></codeline>
</programlisting></para><para>We currently support the following methods to update task parameters from an offloaded cudaFlow:<itemizedlist>
<listitem><para><ref refid="classtf_1_1cudaFlow_1abab3a11129e6286c1de3deecedae8090" kindref="member">tf::cudaFlow::update_kernel</ref> updates the parameters of a kernel task</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a7972c77ba5f533b69e4b1dc55e87374d" kindref="member">tf::cudaFlow::update_copy</ref> updates the parameters of a memcpy task to form a copy task</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1af5f4cd1fc858a7725bbf57db629bdc34" kindref="member">tf::cudaFlow::update_memcpy</ref> updates the parameters of a memcpy task</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a603072d44265de60647a7bcc5aaebace" kindref="member">tf::cudaFlow::update_memset</ref> updates the parameters of a memset task</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a4a319c3e47fc538f6c31a7317c6a17e0" kindref="member">tf::cudaFlow::update_fill</ref> updates the parameters of a memset task to form a fill task</para></listitem><listitem><para><ref refid="classtf_1_1cudaFlow_1a62a042795e4a089ab633d809af6108a6" kindref="member">tf::cudaFlow::update_zero</ref> updates the parameters of a memset task to form a zero task</para></listitem></itemizedlist>
</para><para>Please visit the reference page of <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> for more details.</para><para><simplesect kind="attention"><para>There are quite a few limitations on update methods:<itemizedlist>
<listitem><para>kernel task<itemizedlist>
<listitem><para>The kernel function is not allowed to change</para></listitem></itemizedlist>
</para></listitem><listitem><para>memset and memcpy tasks:<itemizedlist>
<listitem><para>The CUDA device(s) to which the operand(s) was allocated/mapped cannot change</para></listitem><listitem><para>The source/destination memory must be allocated from the same contexts as the original source/destination memory.</para></listitem></itemizedlist>
</para></listitem></itemizedlist>
</para></simplesect>
</para></sect1>
<sect1 id="GPUTaskingcudaFlow_1C6_UsecudaFlowInAStandaloneEnvironment">
<title>Use cudaFlow in a Standalone Environment</title>
<para>You can use <ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref> in a standalone environment without going through <ref refid="classtf_1_1Taskflow" kindref="compound">tf::Taskflow</ref> and offloads it to GPU from the caller thread. All the features we have discussed so far are applicable for the standalone use.</para><para><programlisting filename=".cpp"><codeline><highlight class="normal"><ref refid="classtf_1_1cudaFlow" kindref="compound">tf::cudaFlow</ref><sp/>cf;<sp/><sp/></highlight><highlight class="comment">//<sp/>create<sp/>a<sp/>standalone<sp/>cudaFlow</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dx,<sp/>hx.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>h2d_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(dy,<sp/>hy.data(),<sp/>N).name(</highlight><highlight class="stringliteral">&quot;h2d_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_x<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hx.data(),<sp/>dx,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_x&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>d2h_y<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1af03e04771b655f9e629eb4c22e19b19f" kindref="member">copy</ref>(hy.data(),<sp/>dy,<sp/>N).name(</highlight><highlight class="stringliteral">&quot;d2h_y&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"><ref refid="classtf_1_1cudaTask" kindref="compound">tf::cudaTask</ref><sp/>saxpy<sp/>=<sp/>cf.<ref refid="classtf_1_1cudaFlow_1adb731be71bdd436dfb5e36e6213a9a17" kindref="member">kernel</ref>((N+255)/256,<sp/>256,<sp/>0,<sp/>saxpy,<sp/>N,<sp/>2.0f,<sp/>dx,<sp/>dy)</highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1ab81b4f71a44af8d61758524f0c274962" kindref="member">name</ref>(</highlight><highlight class="stringliteral">&quot;saxpy&quot;</highlight><highlight class="normal">);</highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">saxpy.<ref refid="classtf_1_1cudaTask_1a4a9ca1a34bac47e4c9b04eb4fb2f7775" kindref="member">succeed</ref>(h2d_x,<sp/>h2d_y)<sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>kernel<sp/>runs<sp/>after<sp/><sp/>host-to-device<sp/>copy</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"><sp/><sp/><sp/><sp/><sp/>.<ref refid="classtf_1_1cudaTask_1abdd68287ec4dff4216af34d1db44d1b4" kindref="member">precede</ref>(d2h_x,<sp/>d2h_y);<sp/><sp/></highlight><highlight class="comment">//<sp/>kernel<sp/>runs<sp/>before<sp/>device-to-host<sp/>copy</highlight><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal"></highlight></codeline>
<codeline><highlight class="normal">cf.<ref refid="classtf_1_1cudaFlow_1a85789ed8a1f47704cf1f1a2b98969444" kindref="member">offload</ref>();<sp/><sp/></highlight><highlight class="comment">//<sp/>offload<sp/>and<sp/>run<sp/>the<sp/>standalone<sp/>cudaFlow<sp/>once</highlight></codeline>
</programlisting></para><para><simplesect kind="attention"><para>When using cudaFlow in a standalone environment, it is your choice and responsibility to decide its GPU context and ensure that GPU memory operations are correctly performed. </para></simplesect>
</para></sect1>
    </detaileddescription>
  </compounddef>
</doxygen>
